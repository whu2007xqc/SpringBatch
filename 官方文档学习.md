不错的参考文章： https://www.chkui.com/article/spring/spring_batch_step


## 3. 主要语法/Domain Language of Batch
### Job
job的层次依次分为Job、JobInstance，JobExecution。

> 在Spring Batch中, Job是Step的简单容器. 它联结了多个Step，这些Step在逻辑上归属于一个Flow，并且可以为所有Step配置属性，比如是否可重跑。Job配置包括:
> * Job名称
> * Step实例的定义和执行顺序
> * Job是否可重跑

创建一个SimpleJob：
```java
@Bean
public Job footballJob() {
    return this.jobBuilderFactory.get("footballJob")
                     .start(playerLoad())
                     .next(gameLoad())
                     .next(playerSummarization())
                     .build();
}
```

#### JobParameter
> “一个JobInstance如何区别于另一个？”答案是：JobParameters。  
> JobParameters对象包含了一系列的参数用于启动Job。这些参数既可以用于区分JobInstance，又可以在执行Job期间使用。  
> 更为精确的定义： **JobInstance = Job + identifying JobParameters** .  

注意JobExecution参数：  
* Status： `BatchStatus`对象表示了运行的状态。运行中 = BatchStatus#STARTED。运行失败 = BatchStatus#FAILED。运行成功完成 = BatchStatus#COMPLETED

### Step
> Step拥有单独的StepExecution，需要与Job的JobExecution区分开。  
> 如果Step在正式运行之前就失败了，那么就没有Step运行记录被持久化到DB。StepExecution只会在Step真正开始运行后创建。  

#### StepExecution
参数列表参考：
https://docs.spring.io/spring-batch/docs/current/reference/html/index-single.html#stepexecution

### ExecutionContext
Job和Step都有对应的ExecutionContext，用于保存Job或Step的运行状态。最简单的应用场景就是重跑。  
> 一个JobExecution至少有一个ExecutionContext，一个StepExecution有且仅有一个ExecutionContext。  
> Step在每次commit点保存其上下文，而Job在两个Step运行期间保存上下文。

### JobRepository
用于持久化的工具。为JobLauncher，Job，Step提供了CRUD操作。
使用 Java 配置时，`@EnableBatchProcessing` 注释提供 JobRepository 作为开箱即用自动配置的组件之一。

### JobLauncher
> JobLauncher是一个简单的接口，用来根据JobParameters来启动Job。

## 4. 配置和运行Job/Configuring and Running a Job
### 配置Job/Configuring a Job
#### 重复运行/Restartability
禁止Job重复运行：  
```java
@Bean
public Job footballJob() {
    return this.jobBuilderFactory.get("footballJob")
                     .preventRestart()
                     ...
                     .build();
}
```

#### Listener
> afterJob方法无论是Job运行成功、失败还是停止都会被调用。如果要区分成功和失败，可以从JobExecution中获取状态：

```java
public void afterJob(JobExecution jobExecution){
    if (jobExecution.getStatus() == BatchStatus.COMPLETED ) {
        //job success
    }
    else if (jobExecution.getStatus() == BatchStatus.FAILED) {
        //job failure
    }
}
```
注意顺序：
1. 调用beforeJob -> 2. 调用execute执行job -> 3. 调用afterJob -> 4. JobRepository持久化到DB  
其中步骤2已经将运行状态更新到execution对象中了。  

#### 校验job参数/JobParametersValidator
在job运行之前校验参数，可继承`DefaultJobParametersValidator `接口实现自己的方法。
```java
@Bean
public Job job1() {
    return this.jobBuilderFactory.get("job1")
                     .validator(parametersValidator())
                     ...
                     .build();
}
```

### Java配置/Java Config
Java基础配置包含两部分：`@EnableBatchProcessing`注解与两个builder。  
`@EnableBatchProcessing`提供了搭建Job的基础配置。包括创建了StepScope实例，以及一系列的Bean：  
* JobRepository: bean name "jobRepository"
* JobLauncher: bean name "jobLauncher"
* JobRegistry: bean name "jobRegistry"
* PlatformTransactionManager: bean name "transactionManager"
* JobBuilderFactory: bean name "jobBuilders"
* StepBuilderFactory: bean name "stepBuilders"

*文档说通过配置`@EnableBatchProcessing`注解提供了基础配置，该基础配置是通过`BatchConfigurer`接口来完成的，其中注册了上述所有的Bean。*  
*这个过程是怎么完成的？DataSource是如何获取的？*  

### 配置一个JobRepository
如果要自己配置一个JobRepository，而不使用SpringBatch的默认配置。  
默认配置：  
```java
// This would reside in your BatchConfigurer implementation
@Override
protected JobRepository createJobRepository() throws Exception {
    JobRepositoryFactoryBean factory = new JobRepositoryFactoryBean();
    factory.setDataSource(dataSource); //必须
    factory.setTransactionManager(transactionManager); //必须
    factory.setIsolationLevelForCreate("ISOLATION_SERIALIZABLE");  //设置事务隔离级别，非必须
    factory.setTablePrefix("BATCH_");  //表前缀，当有多个Spring batch程序公用一个库的时候，可能需要修改表名避免冲突。只能修改前缀，表名和字段名不能修改。
    factory.setMaxVarCharLength(1000);
    factory.setDatabaseType("db2");//数据库类型，只有在非标准数据库的情况下需要配置
    return factory.getObject();
}
```
如果没有配置DatabaseType，则会自动探测数据库类型。不同数据库的主键自增策略可能不同，因此需要重写`incrementerFactory`。  
如果以上配置都没有生效，就只能实现每个继承了`SimpleJobRepository`的Dao，以通常Spring的方式来连接数据库。  
setIsolationLevelForCreate方法支持2个值：ISOLATION_SERIALIZABLE、ISOLATION_REPEATABLE_READ，前者是默认配置，类似于@Transactional(isolation = Isolation.SERIALIZABLE)，表示查询和写入都是一次事物，会对事物进行严格的锁定，当事物完成提交后才能进行其他的读写操作，容易死锁。后者是读事物开放，写事物锁定。任何时候都可以快速的读取数据，但是写入事物有严格的事物机制。当一个事物挂起某些记录时，其他写操作必须排队。


### 配置一个JobLauncher
如果要自己配置一个JobLauncher，而不使用SpringBatch的默认配置。  
最基本的实现就是`SimpleJobLauncher`，只需要配置JobRepository。  
```java
// This would reside in your BatchConfigurer implementation
@Override
protected JobLauncher createJobLauncher() throws Exception {
	SimpleJobLauncher jobLauncher = new SimpleJobLauncher();
	jobLauncher.setJobRepository(jobRepository);
	jobLauncher.afterPropertiesSet();
	return jobLauncher;
}
```
`jobLauncher.setTaskExecutor(new SimpleAsyncTaskExecutor()); `通过TaskExecutor转换为异步任务。  
收到HTTP请求的时候，运行Job是异步的，以便`SimpleJobLauncher`能够立刻返回给调用者。

### Job操作
#### 运行Job/Running a Job
运行一个批量Job至少需要一个Job定义和一个JobLauncher，两者既可以在一个上下文中，也可以不在一个上下文。如果通过命令行来启动job，那么JVM会实例化每一个Job，每个Job都有它自己的JobLauncher。如果是通过HttpRequest来启动，那么一般只会有一个JobLauncher。

##### 通过命令行启动Job
继承`CommandLineJobRunner`接口  
> <bash$ java CommandLineJobRunner io.spring.EndOfDayJobConfiguration endOfDay schedule.date(date)=2007/05/05

${jobPath}：io.spring.EndOfDayJobConfiguration  
${jobName}：endOfDay   
${jobParameters}：schedule.date(date)=2007/05/05，格式key=value，可以多个。

##### 通过Web容器启动Job
使用Spring MVC的Controller，将job定义为Bean，并注册到框架之中。  
使用JobLauncher启动Job时，根据job名称（即Bean的名称）从`JobRegistry`获取相应的Bean来启动。

#### 停止Job/Stopping a Job
```java
Set<Long> executions = jobOperator.getRunningExecutions("sampleJob");
jobOperator.stop(executions.iterator().next());
```
Job不会立刻停止，特别是在运行业务代码的时候，框架无法控制。但只要控制权回到框架手中，就会将当前的`JobExecution`的状态设置为`BatchStatus.STOPPED`，再同理处理`StepExecution`。

[Stop Job具体实践参考](https://github.com/whu2007xqc/SpringBatch/blob/main/Stop%20Job.md)
#### 废弃Job/Aborting a Job
Job和Step都可以被置为ABANDONED状态，如果Step被置为废弃，那么在重跑Job的时候该Step会被跳过。  
如果进程被杀死（kill -9 或者服务宕机），JobRepository是无法知道的，此时需要人为将Job/Step的状态置为FAILED或ABANDONED。如果重跑不影响数据（重跑幂等性）的话，只修改Job/Step状态即可。  

### 操作Meta数据/Advanced Meta-Data Usage
[JobOperator、JobLauncher、JobRepository、JobExplorer的作用](https://docs.spring.io/spring-batch/docs/current/reference/html/index-single.html#advancedMetaData)  
JobExplorer用于查询Job元数据，是只读的。

#### 自定义JobExplorer
自定义JobExplorer的方法与自定义JobRepository类似，参考“配置一个JobRepository”一节。  
```java
// This would reside in your BatchConfigurer implementation
@Override
public JobExplorer getJobExplorer() throws Exception {
	JobExplorerFactoryBean factoryBean = new JobExplorerFactoryBean();
	factoryBean.setDataSource(this.dataSource);
	return factoryBean.getObject();
}
```

#### JobRegistry
JobRegistry不是必需的，但对于跟踪当前有哪些Job是可用的会非常有用；对于从应用其他地方收集Job也很有用（Job定义在其他的地方）。JobRegistry提供了从Job名称到Job实例的映射，对于Http方式启动Job的情况下，可以通过Job名称获取Job并运行。    
JobRegistry在`@EnableBatchProcessing`中已经提供了，但也可以自定义JobRegistry。

有两种将Job填充到JobRegistry中的方法：
##### JobRegistryBeanPostProcessor
```java
@Autowired
private JobRegistry jobRegistry;

@Bean
public JobRegistryBeanPostProcessor jobRegistryBeanPostProcessor() {
    JobRegistryBeanPostProcessor postProcessor = new JobRegistryBeanPostProcessor();
    postProcessor.setJobRegistry(jobRegistry);
    return postProcessor;
}
```

##### AutomaticJobRegistrar
AutomaticJobRegistrar是一个基于Job生命周期的组件，它在创建Job上下文的时候注册Job。这样的一个好处是Job中的组件的名称不要求是全局唯一的，比如ItemReader的Bean名称在不同的Job中可以都叫Reader而不会起冲突。

```java
@Bean
public AutomaticJobRegistrar registrar() {

    AutomaticJobRegistrar registrar = new AutomaticJobRegistrar();
    registrar.setJobLoader(jobLoader());
    registrar.setApplicationContextFactories(applicationContextFactories());
    registrar.afterPropertiesSet();
    return registrar;
}
```
`JobLoader`负责管理子上下文的生命周期管理，并将Job注册到`JobRegistry`中。  
`ApplicationContextFactory`是负责创建子上下文（Job或Step的上下文），最常用的是`ClassPathXmlApplicationContextFactory`。它的一个特点是默认会将父上下文的配置复制到子上下文中。  

#### JobOperator
JobOperator`@EnableBatchProcessing`中已经注入了，但也可以自定义JobOperator。  
```java
 @Bean
 public SimpleJobOperator jobOperator(JobExplorer jobExplorer,
                                JobRepository jobRepository,
                                JobRegistry jobRegistry) {

	SimpleJobOperator jobOperator = new SimpleJobOperator();

	jobOperator.setJobExplorer(jobExplorer);
	jobOperator.setJobRepository(jobRepository);
	jobOperator.setJobRegistry(jobRegistry);
	jobOperator.setJobLauncher(jobLauncher);

	return jobOperator;
 }
```

#### JobParametersIncrementer
注意JobOperator提供的`startNextInstance`方法，它会创建一个Job的新实例从头运行Job。JobLauncher新起一个Job依靠不同的JobParameters，而`startNextInstance`使用`JobParametersIncrementer`来新建JobInstance。  
`JobParametersIncrementer`用于返回一个新的JobParameters对象，因此需要定义如何返回新的JobParameters，修改JobParameters中的某个或某几个属性来保证JobParameters在Job中唯一。  
参考官方提供的`RunIdIncrementer`类，其中使用了`JobParametersBuilder`来构造JobParameters对象。  

```java
public class SampleIncrementer implements JobParametersIncrementer {

    public JobParameters getNext(JobParameters parameters) {
        if (parameters==null || parameters.isEmpty()) {
            return new JobParametersBuilder().addLong("run.id", 1L).toJobParameters();
        }
        long id = parameters.getLong("run.id",1L) + 1;
        return new JobParametersBuilder().addLong("run.id", id).toJobParameters();
    }
}
```
```java
@Bean
public Job footballJob() {
    return this.jobBuilderFactory.get("footballJob")
    				 .incrementer(sampleIncrementer())
    				 ...
                     .build();
}
```

## 5. 配置Step/Configuring a Step
一个复杂的Step包含ItemReader、ItemProcessor、ItemWriter组件，其中ItemProcessor是可选的。  
Step是面向Chunk来处理，Reader和Processor读取和处理数据，并计数，当达到Chunk规定的数量时，再将数据列表提交给Writer。可以有效减少事务的数量。  

### 面向Chunk的Step/Chunk-oriented Processing
#### Commit Interval
`stepBuilderFactory.startLimit(1)`设置Step可以被运行的次数（一个Job可以多次运行一个Step），默认是Integer.MAX_VALUE。  

#### 重跑/Restart Logic
`stepBuilderFactory.allowStartIfComplete(true)`设置Step在Completed状态下需要重跑，默认情况下Completed状态的Step会被跳过。  

#### 跳过/Skip Logic
```java
@Bean
public Step step1() {
	return this.stepBuilderFactory.get("step1")
				.<String, String>chunk(10)
				.reader(flatFileItemReader())
				.writer(itemWriter())
				.faultTolerant()
				.skipLimit(10)
				.skip(Exception.class)
				.noSkip(FileNotFoundException.class)
				.build();
}
```
skip中规定的Exception在遇到时会被忽略，但没有规定的依然会导致Step失败。skipLimit设置了忽略次数，超过依然会导致Step失败。noSkip指定了不能被忽略的异常。  

#### 重试/Retry Logic
抛出异常不失败而是重试。

#### 回滚/Rollback
`stepBuilderFactory.noRollback(ValidationException.class)`：一般Step遇到异常，会导致Step控制的事务回滚，可以设置为不回滚。  
`stepBuilderFactory.readerIsTransactionalQueue()`：ItemReader只会一直向下读取，Reader会将读取的数据缓存在Java中，这样遇到回滚的时候，不需要重新读取数据。但遇到消息队列的场景时，消息队列和回滚是绑定的，当回滚时数据会被放回队列之中，因此不需要缓存数据。  

#### 事务属性/Transaction Attributes
单独为Step定义事务属性，包括传播策略、隔离级别、超时时间。

#### Step监听器/Intercepting Step Execution
1. StepExecutionListener： 在Step开始之前（beforeStep()）与结束之后（afterStep()）调用，无论是成功结束还是失败结束。  
2. ChunkListener：一个Chunk对应一个Transaction，在Chunk之前(beforeChunk)或成功之后(afterChunk)或报错之后(afterChunkError)调用。  
3. ItemReadListener  
4. ItemProcessListener  
5. ItemWriteListener  
6. SkipListener：以上所有Listner都用于成功或失败的场景，而SkipListener用于填补Skip场景的空白。因为Skip伴随着异常，所以必须考虑回滚的情况：  
一个item只会调用一次Skip方法；SkipListener只会在事务提交之前调用，确保被listner调用的任何事务型资源不会因为itemWriter的失败而被回滚掉。   

### 控制Step顺序流/Controlling Step Flow
#### 条件流/Conditional Flow
```java
@Bean
public Job job() {
	return this.jobBuilderFactory.get("job")
				.start(stepA())
				.on("*").to(stepB())
				.from(stepA()).on("FAILED").to(stepC())
				.end()
				.build();
}
```
`on()`方法判断Step的ExitStatus，来决定执行下一个Step。* 和? 是通配符。  
如果Step的返回的ExitStatus没有被任何元素捕获，那么会抛出异常导致Job失败。  

##### BatchStatus VS. ExitStatus
BatchStatus是JobExecution和StepExecution的属性，是框架用于记录Job和Step的状态的代码，它的值是固定的那几个。  
ExitStatus是Step在完成时的状态，可以认为是Step结束的返回值，可以在StepListner的afterStep方法中自定义。如果没有自定义，那么和BatchStatus保持一致。  
```java
public class SkipCheckingListener extends StepExecutionListenerSupport {
    public ExitStatus afterStep(StepExecution stepExecution) {
        String exitCode = stepExecution.getExitStatus().getExitCode();
        if (!exitCode.equals(ExitStatus.FAILED.getExitCode()) &&
              stepExecution.getSkipCount() > 0) {
            return new ExitStatus("COMPLETED WITH SKIPS");
        }
        else {
            return null;
        }
    }
}
```

#### 停止的配置/Configuring for stop
Spring Batch框架提供了3个终止元素来修改Job的终止状态，需要注意并不会影响Step的状态，因此可能会产生Step为FAILED而Job为COMPLETED的情况。  

##### 终止Step/Ending at a step
end()：将Job状态置为COMPLETED  
`jobBuilderFactory.get("job").start(step1()).on("FAILED").end()...` Step为FAILED而Job为COMPLETED，因此Job无法被重跑。  

##### 使Step失败/Failing a Step
fail()：将Job状态置为FAILED  

##### 在指定Step停止/Stopping a Job at a Given Step
`.start(step1()).on("COMPLETED").stopAndRestart(step2())` step1成功完成了则Stop，如果Restart则从step2开始运行。  

#### 顺序流决定器/Programmatic Flow Decisions
使用`JobExecutionDecider`，对ExitStatus进行更复杂的处理。  

#### 并行流/Split Flows
使用flow+split配合来实现Step的并行运行。  
```java
@Bean
public Job job(Flow flow1, Flow flow2) {
	return this.jobBuilderFactory.get("job")
				.start(flow1)
				.split(new SimpleAsyncTaskExecutor())
				.add(flow2)
				.next(step4())
				.end()
				.build();
}
```
#### 单独Flow定义与Job间的依赖/Externalizing Flow Definitions and Dependencies Between Jobs
将Step间的顺序流独立出来单独定义，可以复用该顺序流。   
方法一：创建一个flow，指定Step之间的顺序流。  
方法二：创建一个JobStep，指定Job之间的顺序流。  

##### JobStep
```java
@Bean
public Job jobStepJob() {
	return this.jobBuilderFactory.get("jobStepJob")
				.start(jobStepJobStep1(null))
				.build();
}

@Bean
public Step jobStepJobStep1(JobLauncher jobLauncher) {
	return this.stepBuilderFactory.get("jobStepJobStep1")
				.job(job())
				.launcher(jobLauncher)
				.parametersExtractor(jobParametersExtractor())
				.build();
}

@Bean
public Job job() {
	return this.jobBuilderFactory.get("job")
				.start(step1())
				.build();
}

@Bean
public DefaultJobParametersExtractor jobParametersExtractor() {
	DefaultJobParametersExtractor extractor = new DefaultJobParametersExtractor();

	extractor.setKeys(new String[]{"input.file"});

	return extractor;
}
```
即嵌套Job或者说父子Job，如上例中的jobStepJob与job的关系。将job作为jobStepJob的一个Step来处理。  
注意`.parametersExtractor(jobParametersExtractor())`，指定了如何将jobStepJob的jobStepJobStep1的ExecutionContext转换为job的JobParameters。默认是子Job的JobParameters与父Job相同。  

### Job和Step属性的延迟加载/Late Binding of Job and Step Attributes
```java
@StepScope
@Bean
public FlatFileItemReader flatFileItemReader(@Value("#{jobParameters['input.file.name']}") String name) {
	return new FlatFileItemReaderBuilder<Foo>()
			.name("flatFileItemReader")
			.resource(new FileSystemResource(name))
			...
}
```
> @Value("#{jobParameters['input.file.name']}"：从JobParameters里面获取参数。  
> @Value("#{jobExecutionContext['input.file.name']}"：从job上下文获取参数。  
> @Value("#{stepExecutionContext['input.file.name']}"：从step上下文获取参数。  

#### StepScope
@StepScope不能加在Step的Bean上，只能用于Step下的组件的Bean上，比如Tasklet、Reader、Writer等等，Step属于Job层面的定义。  
在Step开始执行的时候，被@StepScope定义的Bean才会被初始化。  

#### JobScope
在多线程或者分区的场景下使用JobScope有一些限制，Spring Batch不控制这些情况下产生的线程，因此可能无法正确使用这些Bean。因此不建议在多线程或者分区的情况下使用JobScope。  


## 6. ItemReaders and ItemWriters
在底层资源（如JMS）拥有事务的情况下，如果事务回滚，ItemReader则有可能会读取到相同的item。如见上文中的`stepBuilderFactory.readerIsTransactionalQueue()`，支持在Read报错时重新读取。  
ItemReader在读取不到任何item的情况下不会抛出异常，当查询结果数量为0时，在第一次Read时返回null。  

### ItemStream
ItemStream是为了在Read、Writer的时候做一些公共的处理，比如打开、关闭资源，将数据持久化等等。一般的Reader-Writer没有提供将数据保存到数据库的方法，如果想从job或step的上下文中保存和读取状态，那么就需要额外实现ItemStream接口。  
一般在自定义的ItemReader和ItemWriter中，需要实现重启Job从断点重跑，那么就要实现ItemStream来持久化状态。

```java
void open(ExecutionContext executionContext) throws ItemStreamException;

void update(ExecutionContext executionContext) throws ItemStreamException;

void close() throws ItemStreamException;
```
update方法支持将数据保存在ExecutionContext之中，便于Job共用。  

### Item代理与Item链/ The Delegate Pattern and Registering with the Step
在一个Step中可以使用多个Processor/Writer来按照顺序处理业务，此时同样可以使用CompositeItem模式来实现：  
```java
@Bean
public CompositeItemProcessor compositeProcessor() {
    //创建 CompositeItemProcessor
    CompositeItemProcessor<Foo,Foobar> compositeProcessor = new CompositeItemProcessor<Foo,Foobar>();
    List itemProcessors = new ArrayList();
    //添加第一个 Processor
    itemProcessors.add(new FooTransformer());
    //添加第二个 Processor
    itemProcessors.add(new BarTransformer());
    //添加链表
    compositeProcessor.setDelegates(itemProcessors);
    return processor;
}
```
如果在Step中`stepBuilderFactory.processor(p1).processor(p2)..`，p2会覆盖p1，最终只执行p2.

### 从数据库中读取数据
#### 通过游标读取数据/ Cursor-based ItemReader Implementations
通过Cursor来处理流式数据传输，Java的ResultSet类也是一种用于操作游标的面向对象的机制，调用next时会将游标移动到下一行。  
Spring Batch 基于游标的 ItemReader 实现在初始化时打开一个游标，并在每次调用 read 时将游标向前移动一行，返回一个可用于处理的映射对象。然后调用 close 方法以确保释放所有资源。  
将数据库查询结果保存到内存中，通过Spring Batch可以实现读取一条数据，写一条数据，然后再次读写的循环。
`JdbcCursorItemReader`通过JDBC的方式读取数据；`HibernateCursorItemReader`通过Hibernate映射来读取数据；`StoredProcedureItemReader`可以通过执行Procedure来读取数据。 

#### 通过分页读取数据/ Paging ItemReader Implementations
分页查询需要指定起始行号与一页的数据行数。  
1. `JdbcPagingItemReader`通过JDBC的方式分页查询，需要定义数据库对象的映射，定义SQL与入参。
```java
return new JdbcPagingItemReaderBuilder<CustomerCredit>()
			.name("creditReader")
			.dataSource(dataSource)
			.queryProvider(queryProvider) //SqlPagingQueryProviderFactoryBean, 定义SQL
			.parameterValues(parameterValues) //SQL参数
			.rowMapper(customerCreditMapper()) //数据库对象的映射关系
			.pageSize(1000) //一页的数据量
			.build();
```

2. `JpaPagingItemReader`使用了Jpa的分页特性，允许使用JPQL语句和EntityManagerFactory。  

3. 使用原始的ItemReader以及数据库的Limit关键字来做分页，以及`MyBatisPagingItemReader`，参考  
[MyBatisPagingItemReader](https://github.com/whu2007xqc/SpringBatch/blob/main/Spring%20batch%E5%88%86%E5%8C%BA%E5%88%86%E9%A1%B51.md)  
[ItemReader+数据库Limit做分页查询](https://github.com/whu2007xqc/SpringBatch/blob/main/Spring%20batch%E5%88%86%E5%8C%BA%E5%88%86%E9%A1%B52.md)  

### 向数据库写数据
通过ItemWriter向数据库写数据时，如果是按照批次的方式flush到数据库，那么其中某条数据写入出错并不会立刻探测到异常，而是在flush时才会探测到。
所以框架并不知道具体是批次中的那一条数据报错，只能对整个批次回滚，而不能针对出错数据做精确的skip，除非每个批次只写一条数据。

### Reusing Existing Services
一般ItemReader和ItemWriter会调用DAO类来操作数据库，但需要在其中实现逻辑时还需要调用其他的Service类。一般在Spring中Service类可以通过依赖注入的方式被调用，但有些场景下Service本身就需要被当作ItemReader或ItemWriter来处理，此时可以使用`ItemReaderAdapter`或`ItemWriterAdapter`, 且Service类可以被重用。  
```java
@Bean
public ItemWriterAdapter itemWriter() {
	ItemWriterAdapter writer = new ItemWriterAdapter();

	writer.setTargetObject(fooService());
	writer.setTargetMethod("processFoo");
	return writer;
}

@Bean
public FooService fooService() {
	return new FooService();
}
```
Service类中需要和read一样，返回null或者一个Object，当返回null时循环终止。  
该功能与通过依赖注入来调用Service差别不大，通过自定义的ItemReader或ItemWriter能更为灵活和强大。  

## 7. Item Processing
在write之前对数据进行处理。

### 串联多个ItemProcessor/ Chaining ItemProcessors
```java
@Bean
public Step step1() {
	return this.stepBuilderFactory.get("step1")
				.<Foo, Foobar>chunk(2)
				.reader(fooReader())
				.processor(compositeProcessor()) //processor代理类
				.writer(foobarWriter())
				.build();
}

@Bean
public CompositeItemProcessor compositeProcessor() {
	List<ItemProcessor> delegates = new ArrayList<>(2);
	delegates.add(new FooProcessor());
	delegates.add(new BarProcessor());

	CompositeItemProcessor processor = new CompositeItemProcessor();

	processor.setDelegates(delegates);

	return processor;
}
```

### [筛选数据、校验输入和错误处理](https://docs.spring.io/spring-batch/docs/current/reference/html/index-single.html#chainingItemProcessors)
注意筛选数据与Skip忽略数据的区别，筛选的前提是所有数据都是合法的，而Skip的数据是不合法的数据。  
当Processor中返回null时，所处理的数据就不会放到write的列表中。  

校验输入的数据是否符合业务逻辑，Spring框架提供了Validator来处理。  
或者通过`BeanValidatingItemProcessor`, 前提是在POJO类中有通过注解来定义校验规则。  

## 8. 并发 / Scaling and Parallel Processing
### 多线程运行Step / Multi-threaded Step
```java
@Bean
public Step sampleStep(TaskExecutor taskExecutor) {
	return this.stepBuilderFactory.get("sampleStep")
				.<String, String>chunk(10)
				.reader(itemReader())
				.writer(itemWriter())
				.taskExecutor(taskExecutor)
				.throttleLimit(20)
				.build();
}
```
通过配置线程池使得Step中的每个Chunk都是单独的线程，最简单的线程池是`SimpleAsyncTaskExecutor`. 多线程会使得Items的执行顺序不是线性的，且也不一定是连续的。  
另外tasklet还有一个节流限制，默认为4，需要增加此限制以提高并发性能。同样其他池化资源（如DataSource）中的配置也需要注意将线程数量调整到与Step中的一样大。  
**由于Step的大多组件都是有状态，且这些组件都不是线程安全的，如果不按线程隔离，那么这些状态都不可用。但是可以使用无状态或线程安全的Step组件。**   
[官方给出的解决案例](https://github.com/spring-projects/spring-batch/tree/main/spring-batch-samples#parallel-sample)  

Spring Batch提供了ItemReader/ItemWriter的一些实现，在javadoc或者代码中检查其是否是线程安全的。或者使用`SynchronizedItemStreamReader`或自定义的同步代码来装饰原来的Reader。  
只要Processor和Writer是Step中花费最多的地方，那么及时同步对Reader进行调用也比单线程更快。  

### 并行运行Step / Parallel Steps
因为业务原因，可以将几个Step同时执行。  
使用Split、TaskExcutor和Flow来实现，注意TaskExecutor必须是异步的才能并行运行，默认是`SyncTaskExecutor`。  

### Remote Chunking
https://docs.spring.io/spring-batch/docs/current/reference/html/index-single.html#remote-chunking

在Step processing之间通过中间件（如MQ）来传输数据，Manager->Middleware->Worker  
Manager是一个单独的process，而Worker可以是多个Process。Manager是一个特殊的Step，其ItemWriter用可以向中间件发送Chunk的特殊版本。  
Worker为中间件支持的标准Listener，基于`ChunkProcessor`接口使用标准的ItemWriter或者ItemProcessor+ItemWriter来处理Chunks。  
该模式的优点是Reader、Writer、Processor组件都是独立的。  

### 分区 / Partitioning
Step(Manager) -> 多个Worker -> Step  
Worker是一个Step的多个实例，可以是远程远程服务也可以是本地线程。  

分区Step由一个特殊的Step实现，`PartitionStep`，以及两个策略接口`PartitionHandler`和`StepExecutionSplitter`。  
具体的代码逻辑是在Worker中实现的，而PartitionStep用来驱动运行整个过程。PartitionStep的配置如下：  
```java
@Bean
public Step step1Manager() {
    return stepBuilderFactory.get("step1.manager")
        .<String, String>partitioner("step1", partitioner())
        .step(step1())
        .gridSize(10)
        .taskExecutor(taskExecutor())
        .build();
}
```
与多线程Step的throttle-limit属性类似，grid-size规定了分页数量。  
Worder的名称类似step1:partition0，Manager Step的名称为get()中定义的名称。  

#### PartitionHandler
PartitionHander是用于远程处理和网络环境的组件，可将StepExecution发送给Workers。它不参与Step的运行，不需要知道Step的输入参数和运行结果，也不干涉Step的重跑等功能。

```java
@Bean
public Step step1Manager() {
    return stepBuilderFactory.get("step1.manager")
        .partitioner("step1", partitioner())
        .partitionHandler(partitionHandler())
        .build();
}

@Bean
public PartitionHandler partitionHandler() {
    TaskExecutorPartitionHandler retVal = new TaskExecutorPartitionHandler();
    retVal.setTaskExecutor(taskExecutor());
    retVal.setStep(step1());
    retVal.setGridSize(10);
    return retVal;
}
```
`gridSize`是分区的数量，需要和`TaskExecutor`线程池的大小匹配。或者可以比可用线程数量大一些来使每一个分区更小。  
`TaskExecutorPartitionHandler`对于 IO 密集型 Step 实例很有用，例如复制大量文件或将文件系统复制到内容管理系统中。它还可以通过提供作为远程调用代理的 Step 实现来用于远程执行（例如使用 Spring Remoting）。

#### Partitioner
与PartitionHandler搭配使用，类似的生成执行上下文作为Step的输入参数。  
